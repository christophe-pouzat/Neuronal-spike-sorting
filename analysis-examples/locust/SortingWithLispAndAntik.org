#+TITLE:     Sorting With Lisp
#+AUTHOR:    Christophe Pouzat
#+EMAIL:     christophe.pouzat@gmail.com
#+DATE:      2012-08-21 mar.
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME: 
#+XSLT:

* Downloading the data
We start by downloading the data from where they are:
#+name: repository-address
: http://xtof.disque.math.cnrs.fr/data/ 
using =wget=. There are 4 data files, one per recording site, named respectively: =Locust_1.dat.gz=, =Locust_2.dat.gz=, =Locust_3.dat.gz=, =Locust_4.dat.gz=.   

#+name: data-file-names
#+BEGIN_SRC emacs-lisp :exports both
  (let ((prefix "Locust_")
        (suffix ".dat")
        (numbers '("1" "2" "3" "4")))
    (mapcar #'(lambda (i) (concatenate 'string prefix i suffix))
         numbers))
  ;;(concatenate 'string address "Locust_1.dat.gz")
#+END_SRC

#+RESULTS: data-file-names
| Locust_1.dat | Locust_2.dat | Locust_3.dat | Locust_4.dat |

#+name: compressed-data-file-names
#+BEGIN_SRC emacs-lisp :var names=data-file-names :exports both
  (mapcar #'(lambda (n) (concatenate 'string n ".gz"))
          names)
#+END_SRC

#+RESULTS: compressed-data-file-names
| Locust_1.dat.gz | Locust_2.dat.gz | Locust_3.dat.gz | Locust_4.dat.gz |

#+name: full-data-file-names
#+BEGIN_SRC emacs-lisp :var address=repository-address :var the-names=compressed-data-file-names :exports both
  (mapcar #'(lambda (n) (concatenate 'string address n))
          the-names)
#+END_SRC

#+RESULTS: full-data-file-names
| http://xtof.disque.math.cnrs.fr/data/Locust_1.dat.gz | http://xtof.disque.math.cnrs.fr/data/Locust_2.dat.gz | http://xtof.disque.math.cnrs.fr/data/Locust_3.dat.gz | http://xtof.disque.math.cnrs.fr/data/Locust_4.dat.gz |

#+name: download-and-gunzip(url=full-data-file-names[0],name=compressed-data-file-names[0])
#+BEGIN_SRC sh
  wget $url && \
      gunzip $name
#+END_SRC

#+CALL: download-and-gunzip[:cache yes :file Locust_1.dat](full-data-file-names[0],compressed-data-file-names[0])

#+RESULTS: download-and-gunzip[:cache yes :file Locust_1.dat](full-data-file-names[0],compressed-data-file-names[0])
: Locust_1.dat

#+CALL: download-and-gunzip[:file Locust_2.dat](full-data-file-names[1],compressed-data-file-names[1])[:cache yes]

#+RESULTS: download-and-gunzip[:file Locust_2.dat](full-data-file-names[1],compressed-data-file-names[1])[:cache yes]
: Locust_2.dat

#+CALL: download-and-gunzip[:cache yes :file Locust_3.dat](full-data-file-names[2],compressed-data-file-names[2])

#+RESULTS: download-and-gunzip[:cache yes :file Locust_3.dat](full-data-file-names[2],compressed-data-file-names[2])
: Locust_3.dat

#+CALL: download-and-gunzip[:cache yes :file Locust_4.dat](full-data-file-names[3],compressed-data-file-names[3])

#+RESULTS: download-and-gunzip[:cache yes :file Locust_4.dat](full-data-file-names[3],compressed-data-file-names[3])
: Locust_4.dat

We can quickly check that the downloaded data look fine:
#+CAPTION: The 20 s of data on each of the four recording sites.
#+LABEL: fig:whole-raw-data
#+ATTR_LaTeX: width=0.8\textwidth
#+name: plot-whole-raw-data-set 
#+BEGIN_SRC sh :cache yes :file whole-raw-data.png :exports both
  graph -T png -I d -a 0.0666667 0 -g 0 -w 3.5 -h 0.8 --reposition 0 0.75 0.25 Locust_1.dat --reposition 0 0.5 0.25 Locust_2.dat --reposition 0 0.25 0.25 Locust_3.dat --reposition 0 0.0 0.25 Locust_4.dat > whole-raw-data.png
#+END_SRC

#+RESULTS[a2c7dbd9e029177e8b26288bab3c942b147eff8e]: plot-whole-raw-data-set
[[file:whole-raw-data.png]]

* Reading the data into Common Lisp session

We are going to use the =ieee-floats= package which is on [[http://www.quicklisp.org/][quicklisp]]. Assuming the package has been installed (see the instruction on quicklisp web site) we load it into our session with:
#+name: load-ieee-floats
#+BEGIN_SRC lisp
  (ql:quickload "ieee-floats")
#+END_SRC

#+RESULTS: load-ieee-floats
| ieee-floats |

We are also going to use the [[http://common-lisp.net/project/gsll/][gsll]] interface to the [[http://www.gnu.org/software/gsl/][gsl]] library meaning that we have to install and compile the latter before loading the former:
#+name: load-gsll
#+BEGIN_SRC lisp
  (ql:quickload "gsll")
#+END_SRC

#+RESULTS: load-gsll
| gsll |

We now define a function reading into our lisp session a file a floats in double format and returning a "foreign" vector:
#+name: define-read-double-to-grid  
#+BEGIN_SRC lisp
  (defun read-double-to-grid (name)
    "Reads a file of double-float data and returns a grid vector"
    (declare (optimize (speed 3)))
    (with-open-file (in name :direction :input
                        :element-type '(unsigned-byte 64))
      (let* ((len (file-length in))
             (res (grid:make-foreign-array 'double-float :dimensions len :initial-element 0d0)))
        (declare (type grid:vector-double-float res))
        (dotimes (i len res)
          (grid:gsetf (grid:aref res i) (ieee-floats:decode-float64 (read-byte in)))))))
#+END_SRC

#+RESULTS: define-read-double-to-grid
: READ-DOUBLE-TO-GRID

We can use this function to create a list of vectors with the raw data. Before doing that wet set the variable =*print-lenght*= to 20 in order to avoid over-filling our session with the printed content of our objects, we also set the variable =*print-foreign-array-readably*= of the =grid= package (automatically loaded with =gsll=) to =nil= inorder to avoid output problems with =slime=:
#+name: set-*print-length*
#+BEGIN_SRC lisp
  (setf *print-length* 20)
  (setf grid:*print-foreign-array-readably* nil)
#+END_SRC

#+RESULTS: set-*print-length*
: NIL

We can now proceed:
#+name: *data-list*
#+begin_src lisp :var data-file-names=data-file-names
  (defparameter *data-list*
    (mapcar #'read-double-to-grid data-file-names)
    "A list of 1 dimensional arrays, each with the raw or derived data of a single electrode")                 
#+end_src

#+RESULTS: *data-list*
: *DATA-LIST*

* Preliminary analysis and processing

** Five-number summary
We are going to compute the [[http://en.wikipedia.org/wiki/Five-number_summary][five-number summary]] of each of our four traces.

Define a function returning the quantiles:
#+name: define-vquantile
#+BEGIN_SRC lisp
  (defun vquantile (data prob)
    (declare (optimize (speed 3)))
    (declare (type grid:vector-double-float data))
    (mapcar #'(lambda (p) 
                (if (or (< p 0d0) (< 1.0d0 p))
                    (error "A probability p must satisfy 0 ≤ p ≤ 1!"))) 
            prob)
    (let* ((len (car (grid:dimensions data)))
           (v (grid:slice data (list (list ':range 0 (1- len))))))
      (declare (type grid:vector-double-float v))
      (setf v (gsll:sort-vector v))        
      (if (= (length prob) 1)
          (gsll:quantile v (car prob))
          (mapcar #'(lambda (p) (gsll:quantile v p)) prob))))
#+END_SRC

#+RESULTS: define-vquantile
: VQUANTILE

We use it keeping two decimals for the display:
#+name: five-numbers-summary
#+BEGIN_SRC lisp :exports both :cache yes
  (mapcar #'(lambda (d) (mapcar #'(lambda (x) 
                                    (/ (round x 0.01) 100d0)) 
                                (vquantile d '(0d0 0.25d0 0.5d0 0.75d0 1d0)))) 
          *data-list*)
#+END_SRC

#+RESULTS[1605423e7a3256f2175ee0c5afb0bddeaaebe2c8]: five-numbers-summary
| -9.07 | -0.37 | -0.03 | 0.33 | 10.63 |
| -8.23 | -0.45 | -0.04 |  0.4 | 11.74 |
| -6.89 | -0.53 | -0.04 | 0.47 |  9.85 |
| -7.35 | -0.49 | -0.04 | 0.43 | 10.56 |

We see that the data range (=maximum= - =minimum=) is similar (close to 20) on the four recording sites. The inter-quartiles ranges are also similar. 

** Were the data normalized
We can check next if some processing like a division by the /standard deviation/ (SD) has been applied.
#+name: sd-of-*data-list*
#+BEGIN_SRC lisp :exports both :cache yes
  (mapcar #'(lambda (x) (/ (round (gsll:standard-deviation x) 0.01) 100d0)) 
          *data-list*)
#+END_SRC

#+RESULTS[3952fda2d808643db48901bf3d1895aeae58a152]: sd-of-*data-list*
| 1.0 | 1.0 | 1.0 | 1.0 |

** Discretization step amplitude

#+name: define-diff
#+BEGIN_SRC lisp
  (defun diff (x &key (lag 1))
    (declare (optimize (speed 3)))
    (declare (type grid:vector-double-float x))
    (declare (fixnum lag))
    (let* ((len (- (car (grid:dimensions x)) lag))
           (res (grid:make-foreign-array 'double-float :dimensions len :initial-element 0d0)))
      (declare (type grid:vector-double-float res))
      (declare (fixnum len))
      (dotimes (i len res)
        (grid:gsetf (grid:aref res i) (- (grid:aref x (+ i lag)) (grid:aref x i))))))
#+END_SRC

#+RESULTS: define-diff
: DIFF

#+name: define-unique
#+BEGIN_SRC lisp
  (defun unique (x)
    (declare (optimize (speed 3)))
    (declare (type grid:vector-double-float x))
    (let* ((len (car (grid:dimensions x)))
           (sorted-x (grid:slice x (list (list ':range 0 (1- len)))))
           (res (grid:make-foreign-array 'double-float :dimensions len :initial-element 0d0))
           (j 0)
           (v 0d0))
      (declare (type grid:vector-double-float sorted-x res))
      (declare (double-float v))
      (declare (fixnum len j))
      (setf sorted-x (gsll:sort-vector sorted-x))
      (setf v (grid:aref sorted-x 0))
      (grid:gsetf (grid:aref res 0) v)
      (do* ((i 1 (1+ i)))
           ((> i (1- len)))
        (setf v (grid:aref sorted-x i))
        (cond ((> v (grid:aref res j))
               (setf j (1+ j))
               (grid:gsetf (grid:aref res j) v))))
      (grid:slice res (list (list ':range 0 j)))))
#+END_SRC

#+RESULTS: define-unique
: UNIQUE

We then get the discretization step for each recording site:
#+name: discretization-step
#+BEGIN_SRC lisp :exports both :cache yes
  (mapcar #'(lambda (x) (reduce #'min (grid:copy-to (diff (unique x))))) 
          *data-list*)
#+END_SRC 

#+RESULTS[c8176f8da473879863aae18abfecf09c1dffe96c]: discretization-step
| 0.006709845078411547 | 0.009194500187932775 | 0.011888432902217971 | 0.009614042128660572 |


** Detecting saturation

Before embarking into a comprehensive analysis of data that we did not record ourselves (of that we recorded so long ago that we do not remember any "remarkable" event concerning them), it can be wise to check that no amplifier or A/D card saturation occurred. We can quickly check for that by looking at the length of the longuest segment of constant value. When saturation occurs the recorded value stays for many sampling points at the same upper or lower saturating level. 
#+name: define-cst-value-segments
#+BEGIN_SRC lisp
  (defun locations (fn seq)
      (declare (optimize (speed 3)))
      (let* ((n (length seq))
             (res (make-array n))
             (i 0))
        (do ((j 0 (1+ j)))
            ((> j (1- n)) (subseq res 0 i))
          (cond ((funcall fn (aref seq j)) 
                 (setf (aref res i) j)
                 (setf i (1+ i)))))))
        
    
  (defun cst-value-segments (data)
    (declare (optimize (speed 3)))
    (labels ((diff (x &key (lag 1))
               (let* ((len (- (length x) lag))
                      (res (make-array len :initial-element 0d0)))
                 (dotimes (i len res)
                   (setf (aref res i) (- (aref x (+ i lag)) (aref x i)))))))
      (let* ((dx (diff data :lag 2))
             (null-derivative (make-array (length dx))))
        (setf null-derivative (map-into null-derivative 
                                        #'(lambda (x) (if (<= (abs x) (* 2 least-positive-double-float)) 1 0)) 
                                        dx))
        (let* ((ddx (diff null-derivative))
               (rise (locations #'(lambda (x) (= x 1)) ddx))
               (fall (locations #'(lambda (x) (= x -1)) ddx)))
          (if (< (aref fall 0) (aref rise 0)) (setf fall (subseq fall 1)))
          (if (> (aref rise (1- (length rise))) (aref fall (1- (length fall)))) (setf rise (subseq rise 0 (1- (length rise)))))
          (setf fall (map-into fall #'- fall rise))
          (let* ((good (locations #'(lambda (x) (< 1 x)) fall))
                 (ngood (length good))
                 (res1 (make-array ngood))
                 (res2 (make-array ngood)))
            (dotimes (i ngood (list res1 res2)) 
                (setf (aref res1 i) (aref rise (aref good i)))
                (setf (aref res2 i) (aref fall (aref good i)))))))))
#+END_SRC

#+RESULTS: define-cst-value-segments
: CST-VALUE-SEGMENTS

Applying =cst-value-segments= to our raw data gives:
#+name: *null-derivative-segments*
#+BEGIN_SRC lisp :exports both :cache yes
  (defparameter *null-derivative-segments* (mapcar #'(lambda (v) (cst-value-segments (grid:copy-to v))) *data-list*))
  *null-derivative-segments*
#+END_SRC

#+RESULTS[730b9cdf679f88c7c991f62f416e7744f5d4f53f]: *null-derivative-segments*
| (44176 109081 197331 277696 285801)                        | (2 2 2 2 2)         |
| (18659 43301 50809 128646 164938 164983 229418 290611)     | (2 2 2 2 2 2 2 2)   |
| (281 9577 50293 104499 119923 187802 213145 227251 272668) | (2 2 2 2 2 2 2 2 2) |
| (91261 238258 252566 271809 275506)                        | (2 2 2 2 2)         |

That is, the longest segment (in sampling points) over which the derivative of the trace is null on each recording siteis:
#+name: longest-segment-null-derivative
#+BEGIN_SRC lisp :exports both :cache yes
  (mapcar #'(lambda (x) (reduce #'max x)) (mapcar #'cadr *null-derivative-segments*))
#+END_SRC

#+RESULTS[e819f64813dff08289dbd85facbd9278b13b8bd2]: longest-segment-null-derivative
| 2 | 2 | 2 | 2 |

We see that for each recording site, the longest segment of constant value is two sampling points long, that is 2/15 ms. There is no ground to worry about saturation here.   

** Plotting the data

#+CAPTION: The first 200 ms of data on each of the four recording sites.
#+LABEL: fig:first-200ms-raw-data
#+ATTR_LaTeX: width=0.8\textwidth
#+name: plot-first-200ms-raw-data-set 
#+BEGIN_SRC sh :cache yes :file first-200ms-raw-data.png :exports both
  graph -T png -I d -a 0.0666667 0 -g 0 -w 3.5 -h 0.8 -x 0 200 --reposition 0 0.75 0.25 Locust_1.dat --reposition 0 0.5 0.25 Locust_2.dat --reposition 0 0.25 0.25 Locust_3.dat --reposition 0 0.0 0.25 Locust_4.dat > first-200ms-raw-data.png
#+END_SRC

#+RESULTS[4e83ccf1807eff7cf8977a809d34f08ef5e83760]: plot-first-200ms-raw-data-set
[[file:first-200ms-raw-data.png]]

* Data renormalization

We are going to use a [[http://en.wikipedia.org/wiki/Median_absolute_deviation][median absolute deviation]] (=MAD=) based renormalization. The goal of the procedure is to scale the raw data such that the noise SD is approximately 1. Since it is not straightforward to obtain a noise SD on data where both signal (i.e., spikes) and noise are present, we use this [[http://en.wikipedia.org/wiki/Robust_statistics][robust]] type of statistic for the SD. We start by defining a function returning the =MAD=:
#+name: define-mad
#+BEGIN_SRC lisp
  (defun mad (data)
    (declare (optimize (speed 3)))
    (declare (type grid:vector-double-float data))
    (let ((med (vquantile data '(0.5d0))))
      (declare (double-float med))
      (labels ((abs-diff (x)
                 (declare (double-float x))
                 (the double-float (abs (- x med)))))
        (the double-float (* 1.4826d0 (vquantile (funcall (grid:elementwise #'abs-diff) data) '(0.5d0)))))))
#+END_SRC

#+RESULTS: define-mad
: MAD

We then get the =MAD= on each recording site:
#+name: MAD-of-each-site
#+BEGIN_SRC lisp :exports both
  (defparameter *MAD-of-each-site* (mapcar #'mad *data-list*))
  (mapcar #'(lambda (x) (/ (round x 0.001) 1000d0)) *MAD-of-each-site*)
#+END_SRC

#+RESULTS: MAD-of-each-site
| 0.517 | 0.627 | 0.74 | 0.684 |

We divide the amplitudes on each recording site by their =MAD=:
#+name: normalize-each-site-to-its-MAD
#+BEGIN_SRC lisp :exports code 
  (setf *data-list* 
        (mapcar #'(lambda (v d) (funcall (grid:elementwise #'(lambda (x) (/ x d))) v)) 
                *data-list* 
                *MAD-of-each-site*))
#+END_SRC

#+RESULTS: normalize-each-site-to-its-MAD
#+begin_example
(#<GRID:VECTOR-DOUBLE-FLOAT
   (0.7477830872306793 -0.5752564794349497 -1.885325069956798
    -2.0280058075383853 -0.7179372170165371 -2.002063855250824
    -3.2602485411975497 -1.4961957856433776 -1.5091667617871585
    -0.49743062257226567 0.04735037546652277 -0.3936628134220202
    -0.7957630738792213 0.5661894212177498 -0.004533529108599931
    0.319740874485917 0.8774928486684861 0.8774928486684861 0.09923428004164549
    0.5532184450739692 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.22082671061609355 -1.5240515584646637 -0.18973288210879047
    -0.17507003951147318 -1.9639368363841823 -0.5416411044444054
    -0.5269782618470881 -0.9228750119746548 0.11818681243487256
    -0.4683268914578189 -0.3510241506792806 0.36745513658926643
    -0.5856296322363572 0.015546914253651532 -0.3363613080819633
    -0.17507003951147318 -0.5416411044444054 0.396780821783901
    -0.8935493267800202 0.5287464051597566 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.10372276074420957 0.8263914316119902 0.4249088366854454
    -0.8116575556883125 -0.859835467079498 -1.7430971759178968
    -1.0204285050501158 -0.5547086949353238 -0.08898888482053194
    1.067280988567917 -0.8116575556883125 -1.1489029354266103
    -0.7313610367030036 -0.1532261000087791 -0.3459377455735206
    -0.3780563531676442 -0.4583528721529531 -0.1853447076029027
    0.8263914316119902 0.39279022909132183 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (-1.05595561288727 -1.9693285163451595 -1.0840593945321284
    0.18061077948648768 -0.8732810321956922 -0.6906064515041143
    -0.6484507790368271 -0.08637514613966454 -0.2128421635415261
    -0.3814648534106749 -0.39551674423310396 -0.6625026698592562
    -0.9013848138405505 -0.6625026698592562 -0.859229141373263
    0.20871456113134582 -1.013799940419983 -0.24094594518638424
    -0.4517243075228202 0.06819565290705518 ...)>)
#+end_example

#+name: write-double-2-file
#+BEGIN_SRC lisp
  (defun write-double-2-file (data file-name)
    (with-open-file (str  file-name :direction :output 
                          :element-type '(unsigned-byte 64)
                          :if-exists :overwrite
                          :if-does-not-exist :create)
      (cond ((listp data)
             (let ((n (length data)))
               (do* ((i 0 (1+ i))
                     (x (ieee-floats:encode-float64 (nth i data))
                        (ieee-floats:encode-float64 (nth i data))))
                    ((>= i (1- n)) 'done)
                 (write-byte x str))))
            (t
             (let ((n (car (grid:dimensions data))))
               (do* ((i 0 (1+ i))
                     (x (ieee-floats:encode-float64 (grid:aref data i))
                        (ieee-floats:encode-float64 (grid:aref data i))))
                    ((>= i (1- n)) 'done)
                 (write-byte x str)))))))
#+END_SRC

#+RESULTS: write-double-2-file
: WRITE-DOUBLE-2-FILE

#+name: define-window
#+BEGIN_SRC lisp
  (defun window (data &key (from 0) (to 200) (step 15))
    (let ((idx-select (list (list ':range (* from step) (1- (* to step))))))
      (grid:slice data idx-select)))
#+END_SRC

#+RESULTS: define-window
: WINDOW

We are going to generate a plot with the first 200 ms of normalized data from the first recording site together with the =MAD= and the =SD= by calling =R= from =Common Lisp= with  [[http://common-lisp.net/project/rcl/][rcl]]. We start by loading =rcl=:
#+name: load-rcl
#+BEGIN_SRC lisp
  (ql:quickload :rcl)
#+END_SRC

#+RESULTS: load-rcl
| :RCL |

We next initialize =R=:
#+name: initialize-R
#+BEGIN_SRC lisp
  (r:r-init)
#+END_SRC

We can now generate the plot with =R= called from =Common Lisp=:
#+name: plot-first-200ms-site-one-normalization-comparison
#+BEGIN_SRC lisp
  (let* ((X (grid:copy-to (window (nth 0 *data-list*) :from 0 :to 200)))
         (MAD-lines  '(-1 1))
         (SD (gsll:standard-deviation (nth 0 *data-list*)))
         (SD-lines (list (* -1 SD) SD)))
      (r:with-device ("first-200ms-site-one-normalization-comparison" :png)
        (r:r "plot.default" X :type "l" :ylab "Amplitude" :xlab "Sample point"
             :main "First 200 ms on site 1.")
        (r:r "abline" :h MAD-lines :col "red")
        (r:r "abline" :h SD-lines :col "blue" :lty 2 :lwd 2)))
#+END_SRC

#+CAPTION: The first 200 ms on the first recording site.
#+LABEL: fig:first-200ms-site-one-normalization-comparison
#+ATTR_LaTeX: width=0.8\textwidth
[[file:first-200ms-site-one-normalization-comparison.png]]

** A quick check that the =MAD= "does its job"
We can check that the =MAD= does its job as a robust estimate of the noise standard deviation by looking at [[http://en.wikipedia.org/wiki/Q-Q_plot][Q-Q plots]] of the whole traces normalized with the MAD and normalized with the "classical" =SD=. We first generate a vector of "percentiles": 
#+name: *prob-seq*
#+BEGIN_SRC lisp
  (defparameter *prob-seq* (iter:iter (iter:for i from 1 to 99) (iter:collect (* 0.01d0 i)))) 
#+END_SRC

#+RESULTS: *prob-seq*
: *PROB-SEQ*

We get the empirical quantiles at each percentile for each of the four recording sites:
#+name: data-list-quantiles
#+BEGIN_SRC lisp 
  (defparameter *data-list-quantiles* 
    (mapcar #'(lambda (seq) (vquantile seq *prob-seq*)) *data-list*))
#+END_SRC

#+RESULTS: data-list-quantiles
: *DATA-LIST-QUANTILES*

We compute the corresponding quantiles of the standard normal distribution:
#+name: *QN*
#+BEGIN_SRC lisp
  (defparameter *QN* (mapcar #'gsll::ugaussian-pinv *prob-seq*))
#+END_SRC

#+RESULTS: *QN*
: *QN*

#+name: define-filter4v
#+BEGIN_SRC lisp :exports none
  (defmacro filter4s (proseq fn &rest proseqs)
    `(let ((res (copy-seq ,proseq)))
      (map-into res ,fn res ,@proseqs)))
#+END_SRC

#+RESULTS: define-filter4v
: FILTER4S

#+BEGIN_SRC lisp :exports none
  (let ((theSD (mapcar #'sd *data-list*))
        (currentSD nil)
        (prefix "quant-channel-")
        (suffix "-norm.dat")
        (file-name nil))
    (do ((i 0 (1+ i)))  
        ((> i 3) 'done)
      (setf currentSD (nth i theSD))
      (print currentSD)
      (setf file-name (concatenate 'string prefix (princ-to-string (1+ i)) "-MAD" suffix))
      (print file-name)
      (write-double-2-file (mapcan #'list (copy-seq *QN*)
                                   (copy-seq (nth i *data-list-quantiles*)))
                           file-name)
      (setf file-name (concatenate 'string prefix (princ-to-string (1+ i)) "-SD" suffix))
      (print file-name)
      (write-double-2-file (mapcan #'list (copy-seq *QN*)
                                   (quantile (filter4s (nth i *data-list*) 
                                                       #'(lambda (x) (/ x currentSD)))
                                             *prob-seq*))
                                   file-name)
      ))
#+END_SRC

#+RESULTS:
: DONE

#+name: check-MAD-job
#+BEGIN_SRC lisp
  (let* ((theSD (mapcar #'gsll:standard-deviation *data-list*))
         (SD-normed-qtl (mapcar #'(lambda (seq) (vquantile seq *prob-seq*))
                                (mapcar #'(lambda (v d) (funcall (grid:elementwise #'(lambda (x) (/ x d))) v))
                                    *data-list*
                                    theSD)))
         (colors '("black" "orange" "blue" "red")))
    (r:with-device ("check-MAD-job" :png)
      (r:r "plot.default" *QN* (nth 0 *data-list-quantiles*) :type "n"
           :ylab "Empirical Quantiles" :xlab "Theoretical Quantiles")
      (r:r "abline" :a 0 :b 1 :col "grey70" :lwd 3)
      (iter:iter (iter:for i from 0 to 3)
                 (r:r "lines" *QN* (nth i *data-list-quantiles*)
                      :col (nth i colors))
                 (r:r "lines" *QN* (nth i SD-normed-qtl)
                      :col (nth i colors) :lty 2))))
#+END_SRC

#+RESULTS: check-MAD-job
: NIL

#+CAPTION: Performances of =MAD= based vs =SD= based normalizations. After normalizing the data of each recording site by its =MAD= (plain colored curves) or its =SD= (dashed colored curves), Q-Q plot against a standard normal distribution were constructed. Colors: site 1, black; site 2, orange; site 3, blue; site 4, red.
[[file:check-MAD-job.png]]

We see that the behavior of the "away from normal" fraction is much more homogeneous for small, as well as for large in fact, quantile values with the =MAD= normalized traces than with the =SD= normalized ones. If we consider automatic rules like the three sigmas we are going to reject fewer events (i.e., get fewer putative spikes) with the =SD= based normalization than with the =MAD= based one. 

* Spike detection

We are going to filter the data slightly using a "box" filter of length 3. That is, the data points of the original trace are going to be replaced by the average of themselves with their two nearest neighbors. We will then scale the filtered traces such that the =MAD= is one on each recording sites and keep only the parts of the signal which above 4: 
#+name: box-filter-data
#+BEGIN_SRC lisp
  (defparameter *derived-data-list* 
    (mapcar #'(lambda (vec)
                (declare (optimize (speed 3)))
                (declare (type grid:vector-double-float vec))
                (let* ((len (car (grid:dimensions vec)))
                       (res (grid:make-foreign-array 'double-float :dimensions len :initial-element 0d0)))
                  (declare (fixnum len))
                  (declare (type grid:vector-double-float res))
                  (dotimes (i (- len 2) res)
                    (grid:gsetf (grid:aref res (1+ i))
                                (/ (+ (grid:aref vec i)
                                      (grid:aref vec (1+ i))
                                      (grid:aref vec (+ i 2))) 3.0d0)))))
            *data-list*))
#+END_SRC

#+RESULTS: box-filter-data
: *DERIVED-DATA-LIST*

#+name: MAD-of-*DERIVED-DATA-LIST*
#+BEGIN_SRC lisp
 (defparameter *MAD-of-each-derived-site* (mapcar #'mad *derived-data-list*))
#+END_SRC

#+RESULTS: MAD-of-*DERIVED-DATA-LIST*
: *MAD-OF-EACH-DERIVED-SITE*

#+name: normalize-each-derived-site-to-its-MAD
#+BEGIN_SRC lisp
  (setf *derived-data-list* 
          (mapcar #'(lambda (v d) (funcall (grid:elementwise #'(lambda (x) (/ x d))) v)) 
                  *derived-data-list* 
                  *MAD-of-each-derived-site*))
#+END_SRC

#+RESULTS: normalize-each-derived-site-to-its-MAD
#+begin_example
(#<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 -0.724109918962403 -1.8976141671574547 -1.9579344789805653
    -2.0072874613812917 -2.5282356089445157 -2.8572554916160255
    -2.648876232590736 -1.4808556491068758 -0.8282995484750478
    -0.35670438331255033 -0.48282867166996246 -0.2634820832222892
    -0.09897214188653426 0.3726230232759633 0.5042309763445673
    0.8771201767056117 0.7838978766153507 0.646806258835555 0.2958517173192777
    ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 -0.6540576721717962 -0.8274981531800637 -1.020209798744805
    -1.1743791151965983 -1.3285484316483915 -0.8724642038118366
    -0.5833967354647243 -0.5577018493894255 -0.3071767101552614
    -0.19797344433524122 -0.24936321648583895 -0.08877017851522102
    -0.39710881141880744 -0.21724460889171535 -0.46134602660705465
    -0.14015995066581877 -0.45492230508822995 0.014009365785974476
    -0.2300920519293648 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 0.6119458840833236 0.19854832182347495 -0.5629735033920359
    -1.5420729929548356 -1.6363566475053273 -1.4985574600853775
    -0.7515408124930193 0.19129573301189867 0.07525431202667796
    -0.40341654953735745 -1.2157064964339022 -0.9183503551592742
    -0.5557209145804595 -0.39616396072578103 -0.5339631481457306
    -0.46143726002996766 0.08250690083825425 0.4668941078517978
    0.43063116379391636 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 -1.761147224470525 -1.231190199167486 -0.7614555631034285
    -0.5928328732342795 -0.9481449697442716 -0.610899590005974
    -0.40614346659343625 -0.29172092703937097 -0.4242101833651307
    -0.6169218289298722 -0.8397446691141047 -0.9541672086681698
    -1.038478553602744 -0.5627216786147887 -0.713277651712243
    -0.44829913906072344 -0.7313443684839376 -0.26763197134377825
    1.1355496979244957 ...)>)
#+end_example

We now rectify the "derived and normalized" traces:
#+name: rectify-derived-normalized-traces
#+BEGIN_SRC lisp
  (setf *derived-data-list* 
            (mapcar #'(lambda (x thres) (funcall (grid:elementwise #'(lambda (v) (if (< v thres) 0d0 v))) x)) 
                    *derived-data-list* 
                    '(4.0d0 4.0d0 4.0d0 4.0d0)))
#+END_SRC

#+RESULTS: rectify-derived-normalized-traces
#+begin_example
(#<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 ...)>
 #<GRID:VECTOR-DOUBLE-FLOAT
   (0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
    0.0 ...)>)
#+end_example

Create a vector containing the element-wise sum of the four rectified channels:
#+name: trace-for-detection
#+BEGIN_SRC lisp
  (defparameter *trace-for-detection* (antik:+ 
                                       (nth 0 *derived-data-list*)
                                       (nth 1 *derived-data-list*)
                                       (nth 2 *derived-data-list*)
                                       (nth 3 *derived-data-list*)))
#+END_SRC

#+RESULTS: trace-for-detection
: *TRACE-FOR-DETECTION*

Define a function detecting =peaks=, that is, local maxima:
#+name: define-peaks
#+BEGIN_SRC lisp
  (defun peaks (vec &key (min-diff 15))
    (declare (optimize (speed 3)))
    (declare (type grid:vector-double-float vec))
    (let ((pos nil)
          (amp nil)
          (current-amp 0d0)
          (max-pos 0)
          (max-amp 0d0)
          (in-it nil))
      (declare (fixnum max-pos))
      (declare (double-float max-amp current-amp))
      (dotimes (i (1- (car (grid:dimensions vec))))
        (setf current-amp (grid:aref vec i))
        (cond ((and (not in-it) (> current-amp 0d0))
               (setf in-it t
                     max-pos i
                     max-amp current-amp))
              ((and in-it (= current-amp 0d0))
               (setf in-it nil)
               (cond ((> (length pos) 0)
                      (cond ((<= (- max-pos (car pos)) min-diff)
                             (pop pos)
                             (pop amp)))))
               (push max-pos pos)
               (push max-amp amp))
              ((and in-it (> current-amp 0d0))
               (if (> current-amp max-amp) (setf max-pos i
                                                 max-amp current-amp)))))
      (coerce (nreverse pos) 'vector)))               
#+END_SRC

#+RESULTS: define-peaks
: PEAKS

Use it:
#+name: *sp-1*
#+BEGIN_SRC lisp
  (defparameter *sp-1* (peaks *trace-for-detection*))
  (defparameter *sp-1-e* (remove-if #'(lambda (pos) (>= pos 150000)) *sp-1*))
  (defparameter *sp-1-l* (remove-if #'(lambda (pos) (< pos 150000)) *sp-1*))
#+END_SRC

#+RESULTS: *sp-1*
: *SP-1-L*


The =mean=, =sd=, minimal and maximal values of the inter-events intervals of =*sp-1*= are (in sampling points):
#+BEGIN_SRC lisp :exports both
  (let* ((len (length *sp-1*))
         (isi (antik:- (subseq *sp-1* 1 len)
                       (subseq *sp-1* 0 (1- len)))))
    (list (gsll:mean (grid:make-foreign-array '(signed-byte 32) :initial-contents (coerce isi 'list)))
          (gsll:standard-deviation (grid:make-foreign-array '(signed-byte 32) :initial-contents (coerce isi 'list)))
          (reduce #'min isi)
          (reduce #'max isi)))
#+END_SRC 

#+RESULTS:
| 173.27241179872757 | 150.02944289364828 | 16 | 1449 |

* Cuts

After detecting our spikes, we must make our cuts in order to create our events' sample. That is, for each detected event we literally cut a piece of data and we do that on the four recording sites. To this end we define function =mk-evts= which in addition to a =pos= argument and a "raw data" argument (=data=) takes an integer argument (=from=) stating how many sampling points we want to keep within the cut before the reference time as well as another integer argument (=to=) stating how many sampling points we want to keep within the cut after the reference time. The function returns essentially a 3D array whose first index corresponds to events, second to sites and third to position within the cut:
#+name: define-make-events
#+BEGIN_SRC lisp
  (defun mk-evts (pos data from to)
    (declare (optimize (debug 3)))
    (declare (fixnum from to))
    (let ((nb-evts (length pos))
          (nb-samp (car (grid:dimensions (car data))))
          (nb-sites (length data))
          (cut-length (+ from to 1))
          (working-pos (copy-seq pos)))
      (setf working-pos (remove-if #'(lambda (i) 
                                       (or (< i from)) (>= i (- nb-samp to)))  
                                   working-pos))
      (setf nb-evts (length working-pos))
      (let* ((res-dim (list (* nb-sites cut-length) nb-evts))
             (res (grid:make-foreign-array 'double-float :dimensions res-dim :initial-element 0d0))
             (offset 0))
        (declare (fixnum offset))
        (declare (type grid:matrix-double-float res))
        (do* ((evt-idx 0 (1+ evt-idx)))
             ((> evt-idx (1- nb-evts)))
          (setf offset (- (aref working-pos evt-idx) from))
          (do ((site-idx 0 (1+ site-idx)))
              ((> site-idx (1- nb-sites)))
            (do ((within-cut-idx 0 (1+ within-cut-idx)))
                ((> within-cut-idx (1- cut-length)))
              (grid:gsetf (grid:aref res (+ within-cut-idx (* site-idx cut-length)) evt-idx)
                          (grid:aref (nth site-idx data)
                                     (+ within-cut-idx offset))))))
        res)))
#+END_SRC

#+RESULTS: define-make-events
: MK-EVTS

** Getting the "right" length for the cuts
The obvious question we must first address is: How long should our cuts be? The pragmatic way to get an answer is:
- Make cuts much longer than what we think is necessary, like 50 sampling points on both sides of the detected event's time.
- Compute robust estimates of the "central" event (with the median) and of the dispersion of the sample around this central event (with the MAD).
- Plot the two together and check when does the MAD trace reach the background noise level (at 1 since we have normalized the data).
- Having the central event allows us to see if it outlasts significantly the region where the MAD is above the background noise level.
Clearly cutting beyond the time at which the MAD hits back the noise level should not bring any useful information as far a classifying the spikes is concerned. So here we perform this task as follows: 
Create an events array corresponding to the first half of the data set:
#+name: *evts-e*
#+BEGIN_SRC lisp
  (defparameter *evts-e* (mk-evts *sp-1-e* *data-list* 49 50))
#+END_SRC

#+RESULTS: *evts-e*
: *EVTS-E*

We then get the events' median and mad:
#+name: *evts-e-med*-and-*evts-e-mad*
#+BEGIN_SRC lisp 
  (defparameter *evts-e-med* (iter:iter (iter:for r :matrix-row *evts-e*) (iter:collect (vquantile r '(0.5d0)))))
  (defparameter *evts-e-mad* (iter:iter (iter:for r :matrix-row *evts-e*) (iter:collect (mad r ))))
#+END_SRC

#+RESULTS: *evts-e-med*-and-*evts-e-mad*
: *EVTS-E-MAD*


Then we create the plot:
#+name: figure-med-and-mad-long
#+BEGIN_SRC lisp 
  (let ((vert (iter:iter (iter:for i from 0 to 40)
                         (iter:collect (* i 10))))
        (horiz  '(0 1)))
    (r:with-device ("med-and-mad-long" :png)
      (r:r "plot.default" *evts-e-med* :type "n" :ylab "Amplitude")
      (r:r "abline" :v vert :col "grey")
      (r:r "abline" :h horiz :col "grey")
      (r:r "lines" *evts-e-med* :lwd 2)
      (r:r "lines" *evts-e-mad* :lwd 2 :col 2)))
#+END_SRC

#+RESULTS: figure-med-and-mad-long
: :NIL

#+CAPTION: Robust estimates of the central event (black) and of the sample's dispersion around the central event (red) obtained with "long" (100 sampling points) cuts. We see clearly that the dispersion is back to noise level 15 points before the peak and 30 points after the peak (on all sites). We also see that the median event is not back to zero 50 points after the peak, we will have to keep his information in mind when we are going to look for superpositions.
[[file:med-and-mad-long.png]]

** Events

Once we are satisfied with our spike detection, at least in a provisory way, and that we have decided on the length of our cuts, we proceed by making cuts around the detected events:

 
